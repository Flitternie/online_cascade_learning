log: ./logs_refactored/
seed: 42

data: 
  name: isear
  env: data.isear
  path: ./data/isear_preprocessed.csv
  num_labels: 7

llm:
  name: Llama2
  source: "./llama_results/isear_llama2_70b_chat.txt"

models:
  - name: LR
    source: sklearn.linear_model
    model: SGDClassifier
    model_args:
      loss: log_loss
    cache_size: 8
    cost: 1 # 110M for bert-base
    wrapper:
      learning_rate: 0.0007
      regularization: 0.0001
      decaying_factor: 0.8
      calibration: 0.15
  - name: BERT-base
    source: transformers
    model: AutoModelForSequenceClassification
    model_args:
      model_name_or_path: bert-base-uncased
      batch_size: 8
      num_epochs: 5
      learning_rate: 1e-5
    cache_size: 16
    cost: 636 # 70B for llama2
    wrapper:
      learning_rate: 0.0007
      regularization: 0.0001
      decaying_factor: 0.9
      calibration: 0.45

mu: 
 - [0.001, 0.01, 0.001]
 - [0.0051, 0.006, 0.0001]
 - [0.006, 0.009, 0.001]