{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lynie/miniconda3/envs/eff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import models.lr as lr\n",
    "import models.bert as bert\n",
    "import os\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_config = ModelArguments()\n",
    "lr_config.num_labels = 4\n",
    "lr_config.cache_size = 8\n",
    "lr_config.cost = 1 #110M for bert-base\n",
    "lr_config.device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Accuracy: 0.94152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:00<00:00, 40414.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model initialized\n",
      "Train Size: 0.1, Accuracy: 0.77192\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.15000000000000002, Accuracy: 0.8228\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.20000000000000004, Accuracy: 0.838\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.25000000000000006, Accuracy: 0.85504\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.30000000000000004, Accuracy: 0.86024\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.3500000000000001, Accuracy: 0.86328\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.40000000000000013, Accuracy: 0.86424\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.45000000000000007, Accuracy: 0.86544\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.5000000000000001, Accuracy: 0.86088\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.5500000000000002, Accuracy: 0.86104\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.6000000000000002, Accuracy: 0.86944\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.6500000000000001, Accuracy: 0.87056\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.7000000000000002, Accuracy: 0.87152\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.7500000000000002, Accuracy: 0.87032\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.8000000000000002, Accuracy: 0.86864\n",
      "Logistic Regression Model initialized\n",
      "Train Size: 0.8500000000000002, Accuracy: 0.87368\n"
     ]
    }
   ],
   "source": [
    "# split into train, val, test\n",
    "import importlib\n",
    "set_seed(42)\n",
    "data_env = 'data.imdb'\n",
    "data_module = importlib.import_module(data_env)\n",
    "data = datasets.Dataset.from_pandas(pd.read_csv(\"./data/imdb_preprocessed.csv\"))\n",
    "\n",
    "llm_labels = open(\"./gpt_results/gpt3.5/imdb_gpt3.5_turbo_1106.txt\", \"r\").readlines()\n",
    "llm_labels = [int(data_module.postprocess(l.strip())) for l in llm_labels]\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLM Accuracy: {correct/total}\")\n",
    "\n",
    "def update_labels(example, idx):\n",
    "    example['llm_label'] = llm_labels[idx]\n",
    "    return example\n",
    "\n",
    "data = data.map(update_labels, with_indices=True)\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['llm_label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "assert correct/total == 1.0 # should be 1.0\n",
    "\n",
    "# split data into train and test\n",
    "data = data.shuffle()\n",
    "data = data.train_test_split(test_size=0.5)\n",
    "\n",
    "results = []\n",
    "for i in np.arange(0.1, 0.9, 0.05):\n",
    "    train_data = data['train'].train_test_split(train_size=i, shuffle=False)\n",
    "    lr_model = lr.LogisticRegressionModelSkLearn(lr_config, data=train_data['train']['text'])\n",
    "\n",
    "    # train model\n",
    "    lr_model.train(train_data['train'])\n",
    "    acc = lr_model.evaluate(data['test'])\n",
    "    print(f\"Train Size: {i}, Accuracy: {acc}\")\n",
    "    results.append((i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.77192),\n",
       " (0.15000000000000002, 0.8228),\n",
       " (0.20000000000000004, 0.838),\n",
       " (0.25000000000000006, 0.85504),\n",
       " (0.30000000000000004, 0.86024),\n",
       " (0.3500000000000001, 0.86328),\n",
       " (0.40000000000000013, 0.86424),\n",
       " (0.45000000000000007, 0.86544),\n",
       " (0.5000000000000001, 0.86088),\n",
       " (0.5500000000000002, 0.86104),\n",
       " (0.6000000000000002, 0.86944),\n",
       " (0.6500000000000001, 0.87056),\n",
       " (0.7000000000000002, 0.87152),\n",
       " (0.7500000000000002, 0.87032),\n",
       " (0.8000000000000002, 0.86864),\n",
       " (0.8500000000000002, 0.87368)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hatespeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Accuracy: 0.8334111931234234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10703/10703 [00:00<00:00, 28166.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 600, Test Size: 5352\n",
      "Logistic Regression Model initialized\n",
      "Recall: 0.3793677204658902\n",
      "Train Size: 600, Accuracy: 0.8017563527653214\n",
      "Train Size: 2700, Test Size: 5352\n",
      "Logistic Regression Model initialized\n",
      "Recall: 0.4925124792013311\n",
      "Train Size: 2700, Accuracy: 0.8223094170403588\n",
      "Train Size: 4900, Test Size: 5352\n",
      "Logistic Regression Model initialized\n",
      "Recall: 0.4242928452579035\n",
      "Train Size: 4900, Accuracy: 0.8503363228699552\n"
     ]
    }
   ],
   "source": [
    "# split into train, val, test\n",
    "import importlib\n",
    "set_seed(42)\n",
    "data_env = 'data.hatespeech'\n",
    "data_module = importlib.import_module(data_env)\n",
    "data = datasets.Dataset.from_pandas(pd.read_csv(\"./data/hatespeech_preprocessed.csv\"))\n",
    "\n",
    "llm_labels = open(\"./gpt_results/gpt3.5/hatespeech_gpt3.5_turbo_1106.txt\", \"r\").readlines()\n",
    "llm_labels = [int(data_module.postprocess(l.strip())) for l in llm_labels]\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLM Accuracy: {correct/total}\")\n",
    "\n",
    "def update_labels(example, idx):\n",
    "    example['llm_label'] = llm_labels[idx]\n",
    "    return example\n",
    "\n",
    "data = data.map(update_labels, with_indices=True)\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['llm_label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "assert correct/total == 1.0 # should be 1.0\n",
    "\n",
    "# split data into train and test\n",
    "data = data.shuffle()\n",
    "data = data.train_test_split(test_size=0.5)\n",
    "# print(\"Test Size: \", len(data['test']))\n",
    "\n",
    "results = []\n",
    "N_range = [600, 2700, 4900]\n",
    "for N in N_range:\n",
    "    # print(f\"Train Size: {N}\")\n",
    "    train_data = data['train'].train_test_split(train_size=N, shuffle=False)\n",
    "    print(f\"Train Size: {len(train_data['train'])}, Test Size: {len(data['test'])}\")\n",
    "    lr_model = lr.LogisticRegressionModelSkLearn(lr_config, data=train_data['train']['text'])\n",
    "\n",
    "    # train model\n",
    "    lr_model.train(train_data['train'])\n",
    "    acc = lr_model.evaluate(data['test'])\n",
    "    print(f\"Train Size: {N}, Accuracy: {acc}\")\n",
    "    results.append((i, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/7666 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7666/7666 [00:00<00:00, 39933.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Accuracy: 0.7034959561701017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7666/7666 [00:00<00:00, 30540.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size:  7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 7666/7666 [00:00<00:00, 213466.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Size:  7666\n",
      "Train Size: 1500, Test Size: 3833\n",
      "Logistic Regression Model initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8459595959595959\n",
      "Train Size: 1500, Accuracy: 0.47456300547873725\n"
     ]
    }
   ],
   "source": [
    "lr_config = ModelArguments()\n",
    "lr_config.num_labels = 7\n",
    "lr_config.cache_size = 8\n",
    "lr_config.cost = 1 #110M for bert-base\n",
    "lr_config.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import importlib\n",
    "data_env = 'data.isear'\n",
    "data_module = importlib.import_module(data_env)\n",
    "\n",
    "set_seed(42)\n",
    "data = datasets.Dataset.from_pandas(pd.read_csv(\"./data/isear_preprocessed.csv\"))\n",
    "\n",
    "isear_to_id = data_module.isear_to_id\n",
    "\n",
    "# Change labels to id\n",
    "data = data.map(lambda e: {'label': isear_to_id[e['label']]})\n",
    "\n",
    "# llm_labels = open(\"./llama_results/isear_llama2_70b_chat.txt\", \"r\").readlines()\n",
    "# llm_labels = [int(l.strip()) for l in llm_labels]\n",
    "llm_labels = open(\"./gpt_results/gpt3.5/isear_gpt3.5_turbo_1106.txt\", \"r\").readlines()\n",
    "llm_labels = [int(data_module.postprocess(l.strip())) for l in llm_labels]\n",
    "# llm_labels = open(\"./\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLM Accuracy: {correct/total}\")\n",
    "\n",
    "def update_labels(example, idx):\n",
    "    example['llm_label'] = llm_labels[idx]\n",
    "    return example\n",
    "\n",
    "data = data.map(update_labels, with_indices=True)\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['llm_label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "assert correct/total == 1.0 # should be 1.0\n",
    "\n",
    "# filter out labels that are -1\n",
    "print(\"Original Size: \", len(data))\n",
    "data = data.filter(lambda e: e['llm_label'] != -1)\n",
    "print(\"Filtered Size: \", len(data))\n",
    "\n",
    "# split data into train and test\n",
    "data = data.shuffle()\n",
    "data = data.train_test_split(test_size=0.5)\n",
    "\n",
    "results = []\n",
    "# N_range = [1200, 1500, 2700]\n",
    "N_range = [1500]\n",
    "# N_range = [5100]\n",
    "for N in N_range:\n",
    "    train_data = data['train'].train_test_split(train_size=N, shuffle=False)\n",
    "    print(f\"Train Size: {len(train_data['train'])}, Test Size: {len(data['test'])}\")\n",
    "    # print(train_data['train'])\n",
    "    # print the possible train data labels\n",
    "    # print(set(train_data['train']['label']))\n",
    "    # print(set(train_data['train']['llm_label']))\n",
    "    lr_model = lr.LogisticRegressionModelSkLearn(lr_config, data=train_data['train']['text'])\n",
    "\n",
    "    # train model\n",
    "    lr_model.train(train_data['train'])\n",
    "    acc = lr_model.evaluate(data['test'])\n",
    "    print(f\"Train Size: {N}, Accuracy: {acc}\")\n",
    "    results.append((i, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, val, test\n",
    "import importlib\n",
    "set_seed(42)\n",
    "data_env = 'data.fever'\n",
    "data_module = importlib.import_module(data_env)\n",
    "data = datasets.Dataset.from_pandas(pd.read_csv(\"./data/fever_preprocessed.csv\"))\n",
    "\n",
    "data = data.map(lambda example: {'label': 0 if example['label'] == 'REFUTES' else 1, 'text': example['text']})\n",
    "\n",
    "# isear_to_id = data_module.isear_to_id\n",
    "\n",
    "# Change labels to id\n",
    "# data = data.map(lambda e: {'label': isear_to_id[e['label']]})\n",
    "\n",
    "llm_labels = open(\"./llama_results/fever_llama2_70b_chat.txt\", \"r\").readlines()\n",
    "llm_labels = [int(l.strip()) for l in llm_labels]\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    # print(data[i]['label'], llm_labels[i])\n",
    "print(f\"LLM Accuracy: {correct/total}\")\n",
    "\n",
    "def update_labels(example, idx):\n",
    "    example['llm_label'] = llm_labels[idx]\n",
    "    return example\n",
    "\n",
    "data = data.map(update_labels, with_indices=True)\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['llm_label'] == llm_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "assert correct/total == 1.0 # should be 1.0\n",
    "\n",
    "# data = data.filter(lambda e: e['llm_label'] != -1)\n",
    "\n",
    "# split data into train and test\n",
    "data = data.shuffle()\n",
    "data = data.train_test_split(test_size=0.5)\n",
    "\n",
    "results = []\n",
    "N_range = [700, 2000, 2800]\n",
    "# N_range = [5100]\n",
    "for N in N_range:\n",
    "    train_data = data['train'].train_test_split(train_size=N, shuffle=False)\n",
    "    print(f\"Train Size: {len(train_data['train'])}, Test Size: {len(data['test'])}\")\n",
    "    lr_model = lr.LogisticRegressionModelSkLearn(lr_config, data=train_data['train']['text'])\n",
    "\n",
    "    # train model\n",
    "    lr_model.train(train_data['train'])\n",
    "    acc = lr_model.evaluate(data['test'])\n",
    "    print(f\"Train Size: {N}, Accuracy: {acc}\")\n",
    "    results.append((i, acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
