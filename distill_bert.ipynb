{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lynie/miniconda3/envs/eff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = ModelArguments()\n",
    "bert_config.num_labels = 4\n",
    "bert_config.model = \"bert-base-uncased\"\n",
    "bert_config.cache_size = 16\n",
    "bert_config.batch_size = 8\n",
    "bert_config.num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAMA Accuracy: 0.6866\n",
      "LLAMA Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.8983: 100%|██████████| 63/63 [00:16<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5440: 100%|██████████| 63/63 [00:16<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.1455: 100%|██████████| 63/63 [00:16<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.0841: 100%|██████████| 63/63 [00:16<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0911: 100%|██████████| 63/63 [00:16<00:00,  3.76it/s]\n",
      "100%|██████████| 625/625 [01:02<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 1.0300: 100%|██████████| 94/94 [00:25<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.6960: 100%|██████████| 94/94 [00:25<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.4701: 100%|██████████| 94/94 [00:25<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.1973: 100%|██████████| 94/94 [00:25<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0358: 100%|██████████| 94/94 [00:25<00:00,  3.70it/s]\n",
      "100%|██████████| 625/625 [01:02<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.9480: 100%|██████████| 125/125 [00:33<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.2929: 100%|██████████| 125/125 [00:33<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2015: 100%|██████████| 125/125 [00:33<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.8878: 100%|██████████| 125/125 [00:33<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.2366: 100%|██████████| 125/125 [00:33<00:00,  3.73it/s]\n",
      "100%|██████████| 625/625 [01:01<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.2626: 100%|██████████| 157/157 [00:42<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.1480: 100%|██████████| 157/157 [00:42<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0182: 100%|██████████| 157/157 [00:42<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0106: 100%|██████████| 157/157 [00:42<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0374: 100%|██████████| 157/157 [00:42<00:00,  3.73it/s]\n",
      "100%|██████████| 625/625 [01:01<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.4971: 100%|██████████| 188/188 [00:50<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.3235: 100%|██████████| 188/188 [00:50<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.1314: 100%|██████████| 188/188 [00:50<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0409: 100%|██████████| 188/188 [00:50<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0210: 100%|██████████| 188/188 [00:50<00:00,  3.73it/s]\n",
      "100%|██████████| 625/625 [01:01<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.9790: 100%|██████████| 219/219 [00:59<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7057: 100%|██████████| 219/219 [00:59<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.4492: 100%|██████████| 219/219 [00:59<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0668: 100%|██████████| 219/219 [00:59<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0159: 100%|██████████| 219/219 [00:59<00:00,  3.70it/s]\n",
      "100%|██████████| 625/625 [01:02<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.3821: 100%|██████████| 250/250 [01:07<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.4376: 100%|██████████| 250/250 [01:07<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.3606: 100%|██████████| 250/250 [01:07<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.3834: 100%|██████████| 250/250 [01:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0209: 100%|██████████| 250/250 [01:07<00:00,  3.71it/s]\n",
      "100%|██████████| 625/625 [01:02<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.2527: 100%|██████████| 282/282 [01:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0464: 100%|██████████| 282/282 [01:16<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2711: 100%|██████████| 282/282 [01:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.2804: 100%|██████████| 282/282 [01:16<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0150: 100%|██████████| 282/282 [01:15<00:00,  3.72it/s]\n",
      "100%|██████████| 625/625 [01:01<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.4429: 100%|██████████| 313/313 [01:24<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.3104: 100%|██████████| 313/313 [01:24<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0951: 100%|██████████| 313/313 [01:24<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0254: 100%|██████████| 313/313 [01:24<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0070: 100%|██████████| 313/313 [01:24<00:00,  3.71it/s]\n",
      "100%|██████████| 625/625 [01:01<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.4597: 100%|██████████| 344/344 [01:32<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.9914: 100%|██████████| 344/344 [01:32<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2736: 100%|██████████| 344/344 [01:32<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.1318: 100%|██████████| 344/344 [01:32<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.3632: 100%|██████████| 344/344 [01:32<00:00,  3.71it/s]\n",
      "100%|██████████| 625/625 [01:01<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.5194: 100%|██████████| 375/375 [01:40<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7607: 100%|██████████| 375/375 [01:41<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.1767: 100%|██████████| 375/375 [01:41<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.5172: 100%|██████████| 375/375 [01:41<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0440: 100%|██████████| 375/375 [01:41<00:00,  3.70it/s]\n",
      "100%|██████████| 625/625 [01:02<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.1491: 100%|██████████| 407/407 [01:49<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0914: 100%|██████████| 407/407 [01:49<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0551: 100%|██████████| 407/407 [01:49<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0206: 100%|██████████| 407/407 [01:49<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0047: 100%|██████████| 407/407 [01:49<00:00,  3.71it/s]\n",
      "100%|██████████| 625/625 [01:02<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6928\n"
     ]
    }
   ],
   "source": [
    "# split into train, val, test\n",
    "set_seed(42)\n",
    "data = datasets.load_from_disk(\"./data/10000_sampled_agnews\")\n",
    "\n",
    "llama_labels = open(\"./llama_results/10000_sampled_agnews_llama.txt\", \"r\").readlines()\n",
    "llama_labels = [int(l.strip()) for l in llama_labels]\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['label'] == llama_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLAMA Accuracy: {correct/total}\")\n",
    "\n",
    "def update_labels(example, idx):\n",
    "    example['llm_label'] = llama_labels[idx]\n",
    "    return example\n",
    "\n",
    "data = data.map(update_labels, with_indices=True)\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(data):\n",
    "    if data[i]['llm_label'] == llama_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLAMA Accuracy: {correct/total}\")\n",
    "\n",
    "# split data into train and test\n",
    "original_data = data.train_test_split(test_size=0.5)\n",
    "\n",
    "original_train_data = original_data['train'].shuffle()\n",
    "\n",
    "results = []\n",
    "for i in np.arange(0.1, 0.9, 0.05):\n",
    "    bert_model = bert.BertModel(bert_config)\n",
    "\n",
    "    train_data = original_train_data.train_test_split(train_size=i, shuffle=False)\n",
    "    dataset = GenericDataset(train_data['train'])\n",
    "    train_dataloader = DataLoader(dataset, batch_size=bert_config.batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = GenericDataset(original_data['test'])\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=bert_config.batch_size, shuffle=False)\n",
    "\n",
    "    # train model\n",
    "    acc = bert_model.train(train_dataloader, val_dataloader)\n",
    "    results.append((i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.7508),\n",
       " (0.15000000000000002, 0.7272),\n",
       " (0.20000000000000004, 0.6932),\n",
       " (0.25000000000000006, 0.6992),\n",
       " (0.30000000000000004, 0.6906),\n",
       " (0.3500000000000001, 0.7136),\n",
       " (0.40000000000000013, 0.7284),\n",
       " (0.45000000000000007, 0.643),\n",
       " (0.5000000000000001, 0.7206),\n",
       " (0.5500000000000002, 0.6826),\n",
       " (0.6000000000000002, 0.7062),\n",
       " (0.6500000000000001, 0.6928)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLAMA Accuracy: 0.6177123260036312\n",
      "LLAMA Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model loaded\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 1.4538: 100%|██████████| 434/434 [01:55<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.2217: 100%|██████████| 434/434 [01:57<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1.4526: 100%|██████████| 434/434 [01:57<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.6048: 100%|██████████| 434/434 [01:57<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.9217: 100%|██████████| 434/434 [01:57<00:00,  3.71it/s]\n",
      "100%|██████████| 186/186 [00:18<00:00,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.28360215053763443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "data = datasets.load_from_disk(\"./data/openbook\")\n",
    "def update_labels(example, idx):\n",
    "    label_to_idx = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "    example['label'] = label_to_idx[example['answerKey']]\n",
    "    example['text'] = '''FACT: {} \\n QUESTION: {}\\n A: {}\\n B: {}\\n C: {}\\n D: {}'''.format(example['fact1'], example['question_stem'], example['choices']['text'][0], example['choices']['text'][1], example['choices']['text'][2], example['choices']['text'][3])\n",
    "    return example\n",
    "data = data.map(update_labels, with_indices=True)\n",
    "\n",
    "# split into train, val, test\n",
    "set_seed(42)\n",
    "train_data = data['train']\n",
    "llama_labels = open(\"./llama_results/openbook_predictions.txt\", \"r\").readlines()\n",
    "llama_labels = [int(l.strip()) for l in llama_labels]\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(train_data):\n",
    "    if train_data[i]['label'] == llama_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLAMA Accuracy: {correct/total}\")\n",
    "\n",
    "def update_labels(example, idx):\n",
    "    example['llm_label'] = llama_labels[idx]\n",
    "    return example\n",
    "\n",
    "train_data = train_data.map(update_labels, with_indices=True)\n",
    "total, correct = 0, 0\n",
    "for i, d in enumerate(train_data):\n",
    "    if train_data[i]['llm_label'] == llama_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(f\"LLAMA Accuracy: {correct/total}\")\n",
    "\n",
    "# split data into train and test\n",
    "train_data = train_data.shuffle()\n",
    "original_data = train_data.train_test_split(test_size=0.3)\n",
    "\n",
    "# results = []\n",
    "# for i in np.arange(0.1, 0.9, 0.05):\n",
    "bert_model = bert.BertModel(bert_config)\n",
    "\n",
    "dataset = GenericDataset(original_data['train'])\n",
    "train_dataloader = DataLoader(dataset, batch_size=bert_config.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = GenericDataset(original_data['test'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=bert_config.batch_size, shuffle=False)\n",
    "\n",
    "# train model\n",
    "acc = bert_model.train(train_dataloader, val_dataloader)\n",
    "# results.append((i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = bert_model.inference(val_dataloader)\n",
    "preds = np.argmax(logits.cpu(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29245283018867924\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "for idx in range(len(preds)):\n",
    "    if logits[idx].cpu().max().item() > 0.8:\n",
    "        if preds[idx].item() == original_data['test']['label'][idx]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(f\"Accuracy: {correct/total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
